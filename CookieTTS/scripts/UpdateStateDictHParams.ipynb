{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['iteration', 'state_dict', 'optimizer', 'learning_rate', 'hparams', 'speaker_id_lookup', 'speaker_name_lookup', 'best_validation_loss', 'average_loss'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "cp_path = r\"G:\\TwiBot\\CookiePPPTTS\\CookieTTS\\_2_ttm\\tacotron2\\NewCPs\\checkpoint_54000\"\n",
    "checkpoint = torch.load(cp_path)\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_hparam_types': {'epochs': (int, False),\n",
       "  'iters_per_checkpoint': (int, False),\n",
       "  'iters_per_validation': (int, False),\n",
       "  'seed': (int, False),\n",
       "  'dynamic_loss_scaling': (bool, False),\n",
       "  'fp16_run': (bool, False),\n",
       "  'distributed_run': (bool, False),\n",
       "  'dist_backend': (str, False),\n",
       "  'dist_url': (str, False),\n",
       "  'cudnn_enabled': (bool, False),\n",
       "  'cudnn_benchmark': (bool, False),\n",
       "  'ignore_layers': (str, True),\n",
       "  'frozen_modules': (str, True),\n",
       "  'print_layer_names_during_startup': (bool, False),\n",
       "  'check_files': (bool, False),\n",
       "  'load_mel_from_disk': (bool, False),\n",
       "  'speakerlist': (str, False),\n",
       "  'dict_path': (str, False),\n",
       "  'p_arpabet': (float, False),\n",
       "  'use_saved_speakers': (bool, False),\n",
       "  'numeric_speaker_ids': (bool, False),\n",
       "  'raw_speaker_ids': (bool, False),\n",
       "  'training_files': (str, False),\n",
       "  'validation_files': (str, False),\n",
       "  'text_cleaners': (str, True),\n",
       "  'silence_value': (float, False),\n",
       "  'silence_pad_start': (int, False),\n",
       "  'silence_pad_end': (int, False),\n",
       "  'max_wav_value': (float, False),\n",
       "  'sampling_rate': (int, False),\n",
       "  'filter_length': (int, False),\n",
       "  'hop_length': (int, False),\n",
       "  'win_length': (int, False),\n",
       "  'n_mel_channels': (int, False),\n",
       "  'mel_fmin': (float, False),\n",
       "  'mel_fmax': (float, False),\n",
       "  'n_symbols': (int, False),\n",
       "  'symbols_embedding_dim': (int, False),\n",
       "  'gate_positive_weight': (int, False),\n",
       "  'gate_threshold': (float, False),\n",
       "  'gate_delay': (int, False),\n",
       "  'max_decoder_steps': (int, False),\n",
       "  'low_vram_inference': (bool, False),\n",
       "  'p_teacher_forcing': (float, False),\n",
       "  'teacher_force_till': (int, False),\n",
       "  'val_p_teacher_forcing': (float, False),\n",
       "  'val_teacher_force_till': (int, False),\n",
       "  'encoder_speaker_embed_dim': (int, False),\n",
       "  'encoder_concat_speaker_embed': (str, False),\n",
       "  'encoder_kernel_size': (int, False),\n",
       "  'encoder_n_convolutions': (int, False),\n",
       "  'encoder_conv_hidden_dim': (int, False),\n",
       "  'encoder_LSTM_dim': (int, False),\n",
       "  'sylpsnet_layer_dims': (int, True),\n",
       "  'emotion_classes': (str, True),\n",
       "  'emotionnet_latent_dim': (int, False),\n",
       "  'emotionnet_encoder_outputs_dropout': (float, False),\n",
       "  'emotionnet_RNN_dim': (int, False),\n",
       "  'emotionnet_classifier_layer_dropout': (float, False),\n",
       "  'emotionnet_ref_enc_convs': (int, True),\n",
       "  'emotionnet_ref_enc_rnn_dim': (int, False),\n",
       "  'emotionnet_ref_enc_use_bias': (bool, False),\n",
       "  'emotionnet_ref_enc_droprate': (float, False),\n",
       "  'auxemotionnet_layer_dims': (int, True),\n",
       "  'auxemotionnet_encoder_outputs_dropout': (float, False),\n",
       "  'auxemotionnet_RNN_dim': (int, False),\n",
       "  'auxemotionnet_classifier_layer_dropout': (float, False),\n",
       "  'torchMoji_attDim': (int, False),\n",
       "  'n_speakers': (int, False),\n",
       "  'speaker_embedding_dim': (int, False),\n",
       "  'use_memory_bottleneck': (bool, False),\n",
       "  'memory_bottleneck_dim': (int, False),\n",
       "  'memory_bottleneck_bias': (bool, False),\n",
       "  'start_token': (str, False),\n",
       "  'stop_token': (str, False),\n",
       "  'hide_startstop_tokens': (bool, False),\n",
       "  'n_frames_per_step': (int, False),\n",
       "  'context_frames': (int, False),\n",
       "  'prenet_dim': (int, False),\n",
       "  'prenet_layers': (int, False),\n",
       "  'prenet_batchnorm': (bool, False),\n",
       "  'p_prenet_dropout': (float, False),\n",
       "  'prenet_speaker_embed_dim': (int, False),\n",
       "  'prenet_noise': (float, False),\n",
       "  'prenet_blur_min': (float, False),\n",
       "  'prenet_blur_max': (float, False),\n",
       "  'attention_rnn_dim': (int, False),\n",
       "  'AttRNN_extra_decoder_input': (bool, False),\n",
       "  'AttRNN_hidden_dropout_type': (str, False),\n",
       "  'p_AttRNN_hidden_dropout': (float, False),\n",
       "  'decoder_rnn_dim': (int, False),\n",
       "  'DecRNN_hidden_dropout_type': (str, False),\n",
       "  'p_DecRNN_hidden_dropout': (float, False),\n",
       "  'decoder_residual_connection': (bool, False),\n",
       "  'second_decoder_rnn_dim': (int, False),\n",
       "  'second_decoder_residual_connection': (bool, False),\n",
       "  'attention_type': (int, False),\n",
       "  'attention_dim': (int, False),\n",
       "  'attention_location_n_filters': (int, False),\n",
       "  'attention_location_kernel_size': (int, False),\n",
       "  'num_att_mixtures': (int, False),\n",
       "  'attention_layers': (int, False),\n",
       "  'delta_offset': (float, False),\n",
       "  'delta_min_limit': (float, False),\n",
       "  'lin_bias': (bool, False),\n",
       "  'initial_gain': (str, False),\n",
       "  'normalize_attention_input': (bool, False),\n",
       "  'normalize_AttRNN_output': (bool, False),\n",
       "  'dynamic_filter_num': (int, False),\n",
       "  'dynamic_filter_len': (int, False),\n",
       "  'postnet_embedding_dim': (int, False),\n",
       "  'postnet_kernel_size': (int, False),\n",
       "  'postnet_n_convolutions': (int, False),\n",
       "  'use_saved_learning_rate': (bool, False),\n",
       "  'learning_rate': (float, False),\n",
       "  'weight_decay': (float, False),\n",
       "  'grad_clip_thresh': (float, False),\n",
       "  'batch_size': (int, False),\n",
       "  'val_batch_size': (int, False),\n",
       "  'use_TBPTT': (bool, False),\n",
       "  'truncated_length': (int, False),\n",
       "  'mask_padding': (bool, False),\n",
       "  'masked_select': (bool, False),\n",
       "  'global_mean_npy': (str, False),\n",
       "  'drop_frame_rate': (float, False),\n",
       "  'LL_SpectLoss': (bool, False),\n",
       "  'melout_LL_scalar': (float, False),\n",
       "  'postnet_LL_scalar': (float, False),\n",
       "  'melout_MSE_scalar': (float, False),\n",
       "  'melout_MAE_scalar': (float, False),\n",
       "  'melout_SMAE_scalar': (float, False),\n",
       "  'postnet_MSE_scalar': (float, False),\n",
       "  'postnet_MAE_scalar': (float, False),\n",
       "  'postnet_SMAE_scalar': (float, False),\n",
       "  'zsClassificationNCELoss': (float, False),\n",
       "  'zsClassificationMAELoss': (float, False),\n",
       "  'zsClassificationMSELoss': (float, False),\n",
       "  'auxClassificationNCELoss': (float, False),\n",
       "  'auxClassificationMAELoss': (float, False),\n",
       "  'auxClassificationMSELoss': (float, False),\n",
       "  'em_kl_weight': (float, False),\n",
       "  'syl_KDL_weight': (float, False),\n",
       "  'pred_sylpsMSE_weight': (float, False),\n",
       "  'pred_sylpsMAE_weight': (float, False),\n",
       "  'predzu_MSE_weight': (float, False),\n",
       "  'predzu_MAE_weight': (float, False),\n",
       "  'DiagonalGuidedAttention_scalar': (float, False),\n",
       "  'DiagonalGuidedAttention_sigma': (float, False),\n",
       "  'use_postnet_discriminator': (bool, False),\n",
       "  'rescale_for_volume': (float, False)},\n",
       " '_model_structure': None,\n",
       " 'epochs': 1000,\n",
       " 'iters_per_checkpoint': 1000,\n",
       " 'iters_per_validation': 1000,\n",
       " 'seed': 1234,\n",
       " 'dynamic_loss_scaling': True,\n",
       " 'fp16_run': True,\n",
       " 'distributed_run': True,\n",
       " 'dist_backend': 'nccl',\n",
       " 'dist_url': 'tcp://127.0.0.1:54321',\n",
       " 'cudnn_enabled': True,\n",
       " 'cudnn_benchmark': False,\n",
       " 'ignore_layers': ['encoder.lstm.weight_ih_l0',\n",
       "  'encoder.lstm.weight_hh_l0',\n",
       "  'encoder.lstm.bias_ih_l0',\n",
       "  'encoder.lstm.bias_hh_l0',\n",
       "  'encoder.lstm.weight_ih_l0_reverse',\n",
       "  'encoder.lstm.weight_hh_l0_reverse',\n",
       "  'encoder.lstm.bias_ih_l0_reverse',\n",
       "  'encoder.lstm.bias_hh_l0_reverse',\n",
       "  'decoder.attention_rnn.weight_ih',\n",
       "  'decoder.attention_rnn.weight_hh',\n",
       "  'decoder.attention_rnn.bias_ih',\n",
       "  'decoder.attention_rnn.bias_hh',\n",
       "  'decoder.attention_layer.query_layer.linear_layer.weight',\n",
       "  'decoder.attention_layer.memory_layer.linear_layer.weight',\n",
       "  'decoder.decoder_rnn.weight_ih',\n",
       "  'decoder.linear_projection.linear_layer.weight',\n",
       "  'decoder.gate_layer.linear_layer.weight'],\n",
       " 'frozen_modules': ['none-N/A'],\n",
       " 'print_layer_names_during_startup': True,\n",
       " 'check_files': True,\n",
       " 'load_mel_from_disk': True,\n",
       " 'speakerlist': '/media/cookie/Samsung 860 QVO/ClipperDatasetV2/filelists/speaker_ids.txt',\n",
       " 'dict_path': '../../dict/merged.dict.txt',\n",
       " 'p_arpabet': 0.5,\n",
       " 'use_saved_speakers': True,\n",
       " 'numeric_speaker_ids': False,\n",
       " 'raw_speaker_ids': False,\n",
       " 'training_files': '/media/cookie/Samsung 860 QVO/ClipperDatasetV2/filelists/mel_train_taca2.txt',\n",
       " 'validation_files': '/media/cookie/Samsung 860 QVO/ClipperDatasetV2/filelists/mel_validation_taca2.txt',\n",
       " 'text_cleaners': ['basic_cleaners'],\n",
       " 'silence_value': -11.52,\n",
       " 'silence_pad_start': 0,\n",
       " 'silence_pad_end': 0,\n",
       " 'max_wav_value': 32768.0,\n",
       " 'sampling_rate': 48000,\n",
       " 'filter_length': 2400,\n",
       " 'hop_length': 600,\n",
       " 'win_length': 2400,\n",
       " 'n_mel_channels': 160,\n",
       " 'mel_fmin': 0.0,\n",
       " 'mel_fmax': 16000.0,\n",
       " 'n_symbols': 179,\n",
       " 'symbols_embedding_dim': 512,\n",
       " 'gate_positive_weight': 10,\n",
       " 'gate_threshold': 0.5,\n",
       " 'gate_delay': 10,\n",
       " 'max_decoder_steps': 3000,\n",
       " 'low_vram_inference': False,\n",
       " 'p_teacher_forcing': 1.0,\n",
       " 'teacher_force_till': 20,\n",
       " 'val_p_teacher_forcing': 0.8,\n",
       " 'val_teacher_force_till': 20,\n",
       " 'encoder_speaker_embed_dim': 64,\n",
       " 'encoder_concat_speaker_embed': 'before_conv',\n",
       " 'encoder_kernel_size': 5,\n",
       " 'encoder_n_convolutions': 3,\n",
       " 'encoder_conv_hidden_dim': 512,\n",
       " 'encoder_LSTM_dim': 768,\n",
       " 'sylpsnet_layer_dims': [32, 32],\n",
       " 'emotion_classes': ['neutral',\n",
       "  'anxious',\n",
       "  'happy',\n",
       "  'annoyed',\n",
       "  'sad',\n",
       "  'confused',\n",
       "  'smug',\n",
       "  'angry',\n",
       "  'whispering',\n",
       "  'shouting',\n",
       "  'sarcastic',\n",
       "  'amused',\n",
       "  'surprised',\n",
       "  'singing',\n",
       "  'fear',\n",
       "  'serious'],\n",
       " 'emotionnet_latent_dim': 32,\n",
       " 'emotionnet_encoder_outputs_dropout': 0.0,\n",
       " 'emotionnet_RNN_dim': 128,\n",
       " 'emotionnet_classifier_layer_dropout': 0.25,\n",
       " 'emotionnet_ref_enc_convs': [32, 32, 64, 64, 128, 128],\n",
       " 'emotionnet_ref_enc_rnn_dim': 64,\n",
       " 'emotionnet_ref_enc_use_bias': False,\n",
       " 'emotionnet_ref_enc_droprate': 0.3,\n",
       " 'auxemotionnet_layer_dims': [256],\n",
       " 'auxemotionnet_encoder_outputs_dropout': 0.0,\n",
       " 'auxemotionnet_RNN_dim': 128,\n",
       " 'auxemotionnet_classifier_layer_dropout': 0.25,\n",
       " 'torchMoji_attDim': 2304,\n",
       " 'n_speakers': 512,\n",
       " 'speaker_embedding_dim': 256,\n",
       " 'use_memory_bottleneck': True,\n",
       " 'memory_bottleneck_dim': 512,\n",
       " 'memory_bottleneck_bias': False,\n",
       " 'start_token': '',\n",
       " 'stop_token': '',\n",
       " 'hide_startstop_tokens': False,\n",
       " 'n_frames_per_step': 1,\n",
       " 'context_frames': 1,\n",
       " 'prenet_dim': 512,\n",
       " 'prenet_layers': 2,\n",
       " 'prenet_batchnorm': False,\n",
       " 'p_prenet_dropout': 0.5,\n",
       " 'prenet_speaker_embed_dim': 0,\n",
       " 'prenet_noise': 0.0,\n",
       " 'prenet_blur_min': 0.0,\n",
       " 'prenet_blur_max': 0.0,\n",
       " 'attention_rnn_dim': 1280,\n",
       " 'AttRNN_extra_decoder_input': True,\n",
       " 'AttRNN_hidden_dropout_type': 'zoneout',\n",
       " 'p_AttRNN_hidden_dropout': 0.1,\n",
       " 'decoder_rnn_dim': 512,\n",
       " 'DecRNN_hidden_dropout_type': 'zoneout',\n",
       " 'p_DecRNN_hidden_dropout': 0.1,\n",
       " 'decoder_residual_connection': False,\n",
       " 'second_decoder_rnn_dim': 512,\n",
       " 'second_decoder_residual_connection': True,\n",
       " 'attention_type': 0,\n",
       " 'attention_dim': 128,\n",
       " 'attention_location_n_filters': 32,\n",
       " 'attention_location_kernel_size': 31,\n",
       " 'num_att_mixtures': 1,\n",
       " 'attention_layers': 1,\n",
       " 'delta_offset': 0.005,\n",
       " 'delta_min_limit': 0.0,\n",
       " 'lin_bias': False,\n",
       " 'initial_gain': 'relu',\n",
       " 'normalize_attention_input': True,\n",
       " 'normalize_AttRNN_output': False,\n",
       " 'dynamic_filter_num': 128,\n",
       " 'dynamic_filter_len': 21,\n",
       " 'postnet_embedding_dim': 512,\n",
       " 'postnet_kernel_size': 5,\n",
       " 'postnet_n_convolutions': 5,\n",
       " 'use_saved_learning_rate': False,\n",
       " 'learning_rate': 1e-06,\n",
       " 'weight_decay': 1e-06,\n",
       " 'grad_clip_thresh': 1.0,\n",
       " 'batch_size': 40,\n",
       " 'val_batch_size': 40,\n",
       " 'use_TBPTT': True,\n",
       " 'truncated_length': 960,\n",
       " 'mask_padding': True,\n",
       " 'masked_select': True,\n",
       " 'global_mean_npy': 'global_mean.npy',\n",
       " 'drop_frame_rate': 0.25,\n",
       " 'LL_SpectLoss': True,\n",
       " 'melout_LL_scalar': 1.0,\n",
       " 'postnet_LL_scalar': 1.0,\n",
       " 'melout_MSE_scalar': 1.0,\n",
       " 'melout_MAE_scalar': 0.0,\n",
       " 'melout_SMAE_scalar': 0.0,\n",
       " 'postnet_MSE_scalar': 1.0,\n",
       " 'postnet_MAE_scalar': 0.0,\n",
       " 'postnet_SMAE_scalar': 0.0,\n",
       " 'zsClassificationNCELoss': 0.15,\n",
       " 'zsClassificationMAELoss': 0.0,\n",
       " 'zsClassificationMSELoss': 0.0,\n",
       " 'auxClassificationNCELoss': 0.15,\n",
       " 'auxClassificationMAELoss': 0.0,\n",
       " 'auxClassificationMSELoss': 0.0,\n",
       " 'em_kl_weight': 0.001,\n",
       " 'syl_KDL_weight': 0.002,\n",
       " 'pred_sylpsMSE_weight': 0.01,\n",
       " 'pred_sylpsMAE_weight': 0.0,\n",
       " 'predzu_MSE_weight': 0.02,\n",
       " 'predzu_MAE_weight': 0.0,\n",
       " 'DiagonalGuidedAttention_scalar': 0.05,\n",
       " 'DiagonalGuidedAttention_sigma': 0.5,\n",
       " 'use_postnet_discriminator': False,\n",
       " 'rescale_for_volume': 0.0,\n",
       " 'n_gpus': 3,\n",
       " 'rank': 0,\n",
       " 'global_mean': tensor([-6.3359, -6.9766, -6.8594, -6.1055, -5.4219, -4.8711, -4.2891, -4.0234,\n",
       "         -3.8125, -3.6992, -3.6641, -3.6758, -3.6582, -3.6055, -3.6953, -3.6816,\n",
       "         -3.6875, -3.7168, -3.7637, -3.7617, -3.7734, -3.8887, -3.9316, -3.9941,\n",
       "         -4.0703, -4.1523, -4.1719, -4.2422, -4.3555, -4.3906, -4.4219, -4.4453,\n",
       "         -4.4648, -4.3984, -4.4414, -4.5000, -4.5039, -4.5000, -4.5039, -4.5273,\n",
       "         -4.4531, -4.5117, -4.5273, -4.5312, -4.5508, -4.4961, -4.4922, -4.6172,\n",
       "         -4.5938, -4.5312, -4.7305, -4.5898, -4.7656, -4.6836, -4.8242, -4.7148,\n",
       "         -4.8711, -4.8242, -4.8359, -4.8867, -4.8828, -4.8828, -4.8594, -4.8984,\n",
       "         -4.8945, -4.8984, -4.9180, -4.9375, -4.9219, -4.9648, -4.9805, -4.9961,\n",
       "         -4.9492, -5.0352, -4.9883, -5.0508, -5.0078, -5.0742, -5.0859, -5.0820,\n",
       "         -5.1211, -5.1328, -5.1602, -5.1875, -5.2109, -5.2109, -5.2539, -5.2773,\n",
       "         -5.2500, -5.3008, -5.2773, -5.3125, -5.3242, -5.3477, -5.3672, -5.3945,\n",
       "         -5.4180, -5.4375, -5.4492, -5.4805, -5.4883, -5.5195, -5.5430, -5.5820,\n",
       "         -5.6250, -5.6797, -5.7422, -5.8164, -5.8828, -5.9453, -5.9961, -6.0508,\n",
       "         -6.1055, -6.1562, -6.1914, -6.2227, -6.2500, -6.2812, -6.3008, -6.3203,\n",
       "         -6.3359, -6.3594, -6.3711, -6.3867, -6.3906, -6.3828, -6.3789, -6.3672,\n",
       "         -6.3633, -6.3594, -6.3477, -6.3516, -6.3711, -6.4023, -6.4375, -6.4727,\n",
       "         -6.5078, -6.5312, -6.5586, -6.5820, -6.6172, -6.6562, -6.6953, -6.7422,\n",
       "         -6.7969, -6.8438, -6.8945, -6.9492, -7.0117, -7.0820, -7.1602, -7.2461,\n",
       "         -7.3320, -7.4219, -7.5234, -7.6172, -7.7305, -7.8516, -7.9805, -8.1484],\n",
       "        device='cuda:0', dtype=torch.float16)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['hparams'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del checkpoint['hparams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, r\"G:\\TwiBot\\CookiePPPTTS\\CookieTTS\\_2_ttm\\tacotron2\\NewCPs\\checkpoint_54000_nhps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.416 avg_max_att]\n"
     ]
    }
   ],
   "source": [
    "print(f'[{0.4159831893:>9.3} avg_max_att]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01.60% avg_max_att]\n"
     ]
    }
   ],
   "source": [
    "print(f'[{0.0159831893:>06.2%} avg_max_att]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16128738711671387"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_iter = 37000\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.230946098662098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "end_iter = 37775\n",
    "end_time = time.time()\n",
    "print( (end_iter-start_iter)/(end_time-start_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
