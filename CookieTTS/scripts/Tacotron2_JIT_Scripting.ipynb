{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n",
    "\n",
    "my_model = Model()\n",
    "my_scripted_model = torch.jit.script(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scripted_model(torch.rand(1, 1, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "D:\\Miniconda\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tacotron... Done\n",
      "Compiling Tacotron Decoder... Done\n",
      "This Tacotron model has been trained for 18000 Iterations.\n",
      "{'yoyo': True, 'yoyo_WN': False, 'n_mel_channels': 160, 'channel_mixing': 'permute', 'mix_first': False, 'n_flows': 6, 'n_group': 20, 'n_early_every': 16, 'n_early_size': 2, 'memory_efficient': 0.0, 'spect_scaling': False, 'upsample_mode': 'normal', 'WN_config': {'n_layers': 8, 'n_channels': 128, 'kernel_size_w': 7, 'kernel_size_h': 7, 'n_layers_dilations_w': None, 'n_layers_dilations_h': 1, 'speaker_embed_dim': 96, 'rezero': False, 'cond_layers': 3, 'cond_activation_func': 'lrelu', 'negative_slope': 0.5, 'cond_hidden_channels': 256, 'cond_padding_mode': 'replicate', 'seperable_conv': True, 'merge_res_skip': False, 'upsample_mode': 'linear', 'cond_kernel_size': 1}, 'speaker_embed': 96, 'cond_layers': 3, 'cond_activation_func': 'lrelu', 'negative_slope': 0.5, 'cond_hidden_channels': 256, 'cond_output_channels': 256, 'cond_residual': True, 'cond_res_rezero': True, 'cond_padding_mode': 'replicate', 'upsample_first': False, 'cond_kernel_size': 2, 'win_length': 2400, 'hop_length': 600, 'preempthasis': 0.0, 'use_logvar_channels': False, 'load_hidden_from_disk': False, 'iso226_empthasis': False}\n",
      "Config File from 'H:/TTCheckpoints/waveflow/4thLargeKernels/AR_6_Flow/config.json' successfully loaded.\n",
      "intializing WaveGlow model... Done!\n",
      "loading WaveGlow checkpoint... Done!\n",
      "initializing Denoiser... Done!\n",
      "WaveGlow trained for 621000 iterations\n",
      "Tokenizing using dictionary from g:\\twibot\\cookieppptts\\CookieTTS\\utils/torchmoji/model/vocabulary.json\n",
      "Loading weights for embed.weight\n",
      "Loading weights for lstm_0.weight_ih_l0\n",
      "Loading weights for lstm_0.weight_hh_l0\n",
      "Loading weights for lstm_0.bias_ih_l0\n",
      "Loading weights for lstm_0.bias_hh_l0\n",
      "Loading weights for lstm_0.weight_ih_l0_reverse\n",
      "Loading weights for lstm_0.weight_hh_l0_reverse\n",
      "Loading weights for lstm_0.bias_ih_l0_reverse\n",
      "Loading weights for lstm_0.bias_hh_l0_reverse\n",
      "Loading weights for lstm_1.weight_ih_l0\n",
      "Loading weights for lstm_1.weight_hh_l0\n",
      "Loading weights for lstm_1.bias_ih_l0\n",
      "Loading weights for lstm_1.bias_hh_l0\n",
      "Loading weights for lstm_1.weight_ih_l0_reverse\n",
      "Loading weights for lstm_1.weight_hh_l0_reverse\n",
      "Loading weights for lstm_1.bias_ih_l0_reverse\n",
      "Loading weights for lstm_1.bias_hh_l0_reverse\n",
      "Loading weights for attention_layer.attention_vector\n",
      "Ignoring weights for output_layer.0.weight\n",
      "Ignoring weights for output_layer.0.bias\n",
      "Loading ARPAbet Dictionary... Done!\n",
      "T2S Initialized and Ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from CookieTTS._5_infer.t2s_server.text2speech import T2S\n",
    "import json\n",
    "\n",
    "# load T2S config\n",
    "with open(r\"G:\\TwiBot\\CookiePPPTTS\\CookieTTS\\_5_infer\\t2s_server\\t2s_config.json\", 'r') as f:\n",
    "    conf = json.load(f)\n",
    "\n",
    "t2s = T2S(conf['workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#t2s.tacotron.decoder.attention_layer = torch.jit.script(t2s.tacotron.decoder.attention_layer)\n",
    "t2s.tacotron.decoder = torch.jit.script(t2s.tacotron.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Postnet(nn.Module):\n",
    "    \"\"\"Postnet\n",
    "        - Five 1-d convolution with 512 channels and kernel size 5\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super(Postnet, self).__init__()\n",
    "        self.b_res = hparams.postnet_residual_connections if hasattr(hparams, 'postnet_residual_connections') else False\n",
    "        self.convolutions = nn.ModuleList()\n",
    "        \n",
    "        for i in range(hparams.postnet_n_convolutions):\n",
    "            is_output_layer = (bool(self.b_res) and bool( i % self.b_res == 0 )) or (i+1 == hparams.postnet_n_convolutions)\n",
    "            layers = [ ConvNorm(hparams.n_mel_channels*(hparams.LL_SpectLoss+1) if i == 0 else hparams.postnet_embedding_dim,\n",
    "                             hparams.n_mel_channels*(hparams.LL_SpectLoss+1) if is_output_layer else hparams.postnet_embedding_dim,\n",
    "                             kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                             padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                             dilation=1, w_init_gain='tanh'), ]\n",
    "            if not is_output_layer:\n",
    "                layers.append(nn.BatchNorm1d(hparams.postnet_embedding_dim))\n",
    "            self.convolutions.append(nn.Sequential(*layers))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_orig = x.clone()\n",
    "        len_convs = len(self.convolutions)\n",
    "        for i, conv in enumerate(self.convolutions):\n",
    "            if (self.b_res and (i % self.b_res == 0)) or (i+1 == len_convs):\n",
    "                x_orig = x_orig + conv(x)\n",
    "                x = x_orig\n",
    "            else:\n",
    "                x = F.dropout(torch.tanh(conv(x)), drop_rate, self.training)\n",
    "        \n",
    "        return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hparams.use_postnet_generator_and_discriminator=False,\n",
    "hparams.adv_postnet_noise_dim=64,\n",
    "hparams.adv_postnet_embedding_dim=512,\n",
    "hparams.adv_postnet_kernel_size=5,\n",
    "hparams.adv_postnet_n_convolutions=6,\n",
    "hparams.adv_postnet_residual_connections=2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANPostnet(nn.Module):\n",
    "    \"\"\"GANPostnet\n",
    "        - Five 1-d convolution with 512 channels and kernel size 5\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super(Postnet, self).__init__()\n",
    "        self.b_res = hparams.adv_postnet_residual_connections if hasattr(hparams, 'adv_postnet_residual_connections') else False\n",
    "        self.convolutions = nn.ModuleList()\n",
    "        self.noise_dim = hparams.adv_postnet_noise_dim\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        \n",
    "        for i in range(hparams.adv_postnet_n_convolutions):\n",
    "            is_output_layer = (self.b_res and bool( i % self.b_res == 0 )) or (i+1 == hparams.adv_postnet_n_convolutions)\n",
    "            layers = [ ConvNorm(\n",
    "                             (hparams.n_mel_channels*(hparams.LL_SpectLoss+1))+self.noise_dim if i==0 else hparams.adv_postnet_embedding_dim,\n",
    "                             hparams.n_mel_channels if is_output_layer else hparams.adv_postnet_embedding_dim,\n",
    "                             kernel_size=hparams.adv_postnet_kernel_size, stride=1,\n",
    "                             padding=int((hparams.adv_postnet_kernel_size - 1) / 2),\n",
    "                             dilation=1, w_init_gain='tanh'), ]\n",
    "            if not is_output_layer:\n",
    "                layers.append(nn.BatchNorm1d(hparams.adv_postnet_embedding_dim))\n",
    "            self.convolutions.append(nn.Sequential(*layers))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, dec_T = x.shape# [B, n_mel+logvar, dec_T]\n",
    "        rand_noise = torch.randn(B, self.noise_dim, dec_T, device=x.device, dtype=x.dtype)# -> [B, noise, dec_T]\n",
    "        x_orig = torch.cat((x, rand_noise), dim=1)# [B, n_mel+logvar, dec_T] -> [B, n_mel+logvar+noise, dec_T]\n",
    "        len_convs = len(self.convolutions)\n",
    "        for i, conv in enumerate(self.convolutions):\n",
    "            if (self.b_res and (i % self.b_res == 0)) or (i+1 == len_convs):\n",
    "                x = conv(x)# [B, conv_dim, dec_T] -> [B, n_mel+logvar+noise, dec_T]\n",
    "                x = x_orig = x_orig + x# [B, n_mel+logvar+noise, dec_T] + [B, n_mel+logvar+noise, dec_T] -> [B, n_mel+logvar+noise, dec_T]\n",
    "            else:\n",
    "                x = F.dropout(torch.tanh(conv(x)), drop_rate, self.training)# [B, n_mel+logvar+noise, dec_T] -> [B, conv_dim, dec_T]\n",
    "        \n",
    "        return x_orig[:, :self.n_mel_channels]# [B, conv_dim, dec_T] -> [B, n_mel, dec_T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Adversarial Postnet Discriminator) - Learns the difference between real and fake spectrograms, teaches the postnet generator how to make convincing looking outputs.\n",
    "dis_postnet_embedding_dim=128,\n",
    "dis_postnet_kernel_size=5,\n",
    "dis_postnet_n_convolutions=6,\n",
    "dis_postnet_residual_connections=2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( range(10)[1:-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Output Value?\n",
      "tensor([True, True, True, True, True])\n",
      "\n",
      "Correct Output Gradients?\n",
      "tensor([True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@torch.jit.script\n",
    "def scale_grads(input, scale: float):\n",
    "    \"\"\"\n",
    "    Change gradient magnitudes\n",
    "    Note: Do not use @torch.jit.script on pytorch <= 1.6 with this function!\n",
    "          no_grad() and detach() do not work correctly till version 1.7 with JIT script.\n",
    "    \"\"\"\n",
    "    out = input.clone()\n",
    "    out *= scale               # multiply tensor\n",
    "    out.detach().mul_(1/scale) # reverse multiply without telling autograd\n",
    "    return out\n",
    "\n",
    "x = torch.ones(5, requires_grad=True)\n",
    "scale = 0.1\n",
    "\n",
    "output = scale_grads(x, scale)\n",
    "output.sum().backward()\n",
    "\n",
    "print(\"Correct Output Value?\")\n",
    "print(output == x)\n",
    "print(\"\\nCorrect Output Gradients?\")\n",
    "print(x.grad == scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDiscriminator(nn.Module):\n",
    "    \"\"\"GANDiscriminator\n",
    "        - Five 1-d convolution with 512 channels and kernel size 5\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super(Postnet, self).__init__()\n",
    "        self.b_res = hparams.dis_postnet_residual_connections if hasattr(hparams, 'dis_postnet_residual_connections') else False\n",
    "        self.convolutions = nn.ModuleList()\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        \n",
    "        for i in range(hparams.dis_postnet_n_convolutions):\n",
    "            is_output_layer = (self.b_res and bool( i % self.b_res == 0 )) or (i+1 == hparams.dis_postnet_n_convolutions)\n",
    "            layers = [ ConvNorm(\n",
    "                             hparams.n_mel_channels if i == 0 else hparams.dis_postnet_embedding_dim,\n",
    "                             hparams.dis_postnet_embedding_dim,\n",
    "                             kernel_size=hparams.dis_postnet_kernel_size, stride=1,\n",
    "                             padding=int((hparams.dis_postnet_kernel_size - 1) / 2),\n",
    "                             dilation=1, w_init_gain='tanh'), ]\n",
    "            if not is_output_layer:\n",
    "                layers.append(nn.BatchNorm1d(hparams.dis_postnet_embedding_dim))\n",
    "            self.convolutions.append(nn.Sequential(*layers))\n",
    "        \n",
    "        self.end_conv = ConvNorm( hparams.dis_postnet_embedding_dim, 1, kernel_size=3, padding=0, w_init_gain='tanh')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        len_convs = len(self.convolutions)\n",
    "        for i, conv in enumerate(self.convolutions):\n",
    "            if i==0:\n",
    "                x = x_res = conv(x)\n",
    "            else:\n",
    "                if (self.b_res and (i % self.b_res == 0)) or (i+1 == len_convs):\n",
    "                    x = x_res = x_res + conv(x)# [B, conv_dim, dec_T] + [B, conv_dim, dec_T] -> [B, conv_dim, dec_T]\n",
    "                else:\n",
    "                    x = F.dropout(torch.tanh(conv(x)), drop_rate, self.training)# [B, conv_dim, dec_T] -> [B, conv_dim, dec_T]\n",
    "        \n",
    "        pred_fakeness = self.end_conv(x_res)# [B, conv_dim, dec_T] -> [B, 1, dec_T-2]\n",
    "        pred_fakeness = pred_fakeness.mean(dim=2).squeeze(1).squeeze(1)# [B, 1, dec_T-2] -> [B, 1, 1] -> [B, 1] -> [B]\n",
    "        \n",
    "        return pred_fakeness.sigmoid()# [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.rand(5, 1, 2).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
