{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from CookieTTS.utils.dataset.utils import load_wav_to_torch, load_filepaths_and_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalBatchNorm1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional Batch Normalization\n",
    "    https://github.com/yanggeng1995/GAN-TTS/blob/master/models/generator.py#L121-L144\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, z_channels=128):\n",
    "        super(ConditionalBatchNorm1d).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.z_channels = z_channels\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features, affine=False)\n",
    "        \n",
    "        self.layer = nn.utils.spectral_norm(nn.Linear(z_channels, num_features * 2))\n",
    "        self.layer.weight.data.normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
    "        self.layer.bias.data.zero_()             # Initialise bias at 0\n",
    "    \n",
    "    def forward(self, inputs, noise):\n",
    "        outputs = self.batch_norm(inputs)\n",
    "        gamma, beta = self.layer(noise).chunk(2, dim=1)\n",
    "        gamma = gamma.view(-1, self.num_features, 1)\n",
    "        beta = beta.view(-1, self.num_features, 1)\n",
    "        \n",
    "        outputs = gamma * outputs + beta\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, z_dim=None, dilation=1, kernel_size=1, act_func=nn.LeakyReLU(negative_slope=0.1, inplace=True), bias=True, scale:int=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = (kernel_size - 1)//2\n",
    "        self.dilation = dilation\n",
    "        self.bias = bias\n",
    "        if scale != 1:\n",
    "            self.scale = scale\n",
    "        \n",
    "        if self.z_dim is not None:\n",
    "            self.bn = ConditionalBatchNorm1d(self.in_dim, self.z_dim)\n",
    "        self.act_func = act_func\n",
    "        \n",
    "        self.conv = nn.Conv1d(self.in_dim, self.out_dim, self.kernel_size, padding=self.padding, dilation=self.dilation, bias=bias)\n",
    "    \n",
    "    def forward(self, x, z=None):                                 # [B, in_dim, T]\n",
    "        if hasattr(self, 'bn'):\n",
    "            x = self.bn(x, z)\n",
    "        x = self.act_func(x)\n",
    "        if hasattr(self, 'scale'):\n",
    "            x = F.interpolate(x, scale_factor=self.scale) # [B, in_dim, T]   -> [B, in_dim, x*T]\n",
    "        x = self.conv(x)                                  # [B, in_dim, x*T] -> [B, out_dim, x*T]\n",
    "        return x                                          # [B, out_dim, x*T]\n",
    "\n",
    "\n",
    "class GBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, z_dim, kernel_size=3, dilations=[1,2,4,8], scale:int=1, upsample_block_id=0, res_block_id=1):\n",
    "        super(GBlock, self).__init__()\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        self.upsample_block_id = upsample_block_id\n",
    "        self.res_block_id = res_block_id\n",
    "        self.scale = scale\n",
    "        \n",
    "        for i, dilation in enumerate(dilations):\n",
    "            in_dim = input_dim if i == 0 else output_dim\n",
    "            dilation = dilations[i]\n",
    "            scale_f = scale if i == self.upsample_block_id else int(1)\n",
    "            resblock = ResidualBlock(in_dim, output_dim, z_dim=z_dim, dilation=dilation, kernel_size=kernel_size, scale=scale_f)\n",
    "            self.resblocks.append(resblock)\n",
    "        \n",
    "        self.skip_conv = nn.Conv1d(input_dim, output_dim, 1)\n",
    "    \n",
    "    def forward(self, h, z):\n",
    "        h = torch.cat((h, z), dim=1)# -> [B, input_dim, T]\n",
    "        \n",
    "        scaled_h = F.interpolate(h, scale_factor=self.scale) if self.scale != 1 else h# [B, input_dim, T] -> [B, input_dim, x*T]\n",
    "        residual = self.skip_conv(h)# [B, input_dim, x*T] -> [B, output_dim, x*T]\n",
    "        \n",
    "        for i, resblock in enumerate(self.resblocks): # [B, input_dim, T] -> [B, output_dim, x*T]\n",
    "            h = resblock(h)\n",
    "            if i == self.res_block_id:\n",
    "                h += residual\n",
    "                residiual = h\n",
    "        \n",
    "        return h + residual # [B, output_dim, x*T]\n",
    "\n",
    "\n",
    "class ConditionalDBlock(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(ConditionalDBlock, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(DBlock, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.start = nn.Conv1d(hp.in_channels, hp.decoder_dims[0], kernel_size=3)\n",
    "        \n",
    "        self.Gblocks = nn.ModuleList([\n",
    "            GBlock(hp.decoder_dims[0], hp.decoder_dims[0], hp.z_dim, kernel_size=hp.gblock_kernel_size, dilations=hp.dilations, scale=hp.decoder_scales[0]),\n",
    "        ])\n",
    "        for i, dim in enumerate(hp.decoder_dims[:-1]):\n",
    "            in_dim = hp.decoder_dims[i]\n",
    "            out_dim = hp.decoder_dims[i+1]\n",
    "            scale = hp.decoder_scales[i+1]\n",
    "            gblock = GBlock(in_dim, out_dim, hp.z_dim, kernel_size=hp.gblock_kernel_size, dilations=hp.dilations, scale=scale)\n",
    "            self.Gblocks.append(gblock)\n",
    "        \n",
    "        self.end = nn.Conv1d(hp.decoder_dims[-1], 1, kernel_size=3)\n",
    "    \n",
    "    def forward(self, x, z):\n",
    "        x = self.start(x)\n",
    "        for gblock in self.Gblocks:\n",
    "            x = gblock(x, z)\n",
    "        x = self.end(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GANTTS(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(GANTTS, self).__init__()\n",
    "        #self.encoder = Encoder(hp) # Text -> Encoder Features\n",
    "        #self.durpred = DurPred(hp) # Encoder Features -> Durations\n",
    "        self.decoder = Decoder(hp) # Durations + Encoder Features -> Audio\n",
    "        self.z_dim = hp.z_dim\n",
    "    \n",
    "    def parse_encoder_outputs(self, encoder_outputs, durations):\n",
    "        \"\"\"\n",
    "        Acts as Monotonic Attention for Encoder Outputs.\n",
    "        \n",
    "        [B, enc_T, enc_dim] x [B, enc_T, durations] -> [B, dec_T, enc_dim]\n",
    "        \"\"\"\n",
    "        return attention_contexts\n",
    "    \n",
    "    @torch.jit.script\n",
    "    def generate_noise(x, z_dim:int):\n",
    "        noise = torch.randn(x.shape[0], z_dim, 1, device=x.device, dtype=x.dtype)\n",
    "        return noise\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoder_outputs, durations, *_ = inputs\n",
    "        \n",
    "        noise = self.generate_noise(encoder_outputs, self.z_dim)\n",
    "        \n",
    "        attention_contexts = self.parse_encoder_outputs(encoder_outputs, durations)\n",
    "        \n",
    "        pred_audio = self.decoder(attention_contexts, noise)\n",
    "        \n",
    "        return pred_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"blah\" is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
